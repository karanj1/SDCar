{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from collections import deque\n",
    "import glob\n",
    "import imageio\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pickled distortion matrix\n",
    "with open('camera_cal/output/cal_dist_pickle.p', mode='rb') as f:\n",
    "    dist_pickle = pickle.load(f)\n",
    "    mtx = dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in an image\n",
    "#img = cv2.imread('test_image.png')\n",
    "\n",
    "# TODO: Write a function that takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "def cal_undistort(img):\n",
    "    # Use cv2.calibrateCamera() and cv2.undistort()\n",
    "    #ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[0:2], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    #undist = np.copy(img)  # Delete this line\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to grayscale\n",
    "def to_grayscale(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=85, thresh_max=195):\n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    sobel_binary = np.zeros_like(scaled_sobel)\n",
    "    sobel_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    # Return this mask as your binary_output image\n",
    "    #binary_output = np.copy(img) # Remove this line\n",
    "    return sobel_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb_thresh(img):\n",
    "    # R & G thresholds so that yellow lanes are detected well.\n",
    "    color_threshold = 150\n",
    "    R = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    color_combined = np.zeros_like(R)\n",
    "    r_g_condition = (R > color_threshold) & (G > color_threshold)\n",
    "    return r_g_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    absgraddir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # Create a binary mask where direction thresholds are met # no scaling\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    return dir_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hls_select(img, s_thresh=(110, 255)):\n",
    "    # Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    L = hls[:,:,1]\n",
    "    S = hls[:,:,2]\n",
    "    # Apply a threshold to the S channel\n",
    "    s_binary = np.zeros_like(S)\n",
    "    s_binary[(S > s_thresh[0]) & (S <= s_thresh[1])] = 1\n",
    "    \n",
    "    # Return a binary image of threshold result\n",
    "    #binary_hls[((s_binary == 1))] =1\n",
    "\n",
    "    return s_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mask_ROI(image):\n",
    "    # apply the region of interest mask\n",
    "    height,width = image.shape\n",
    "    #print(image.shape,height,width)\n",
    "    mask = np.zeros_like(image)\n",
    "    #region_of_interest_vertices = np.array([[0,height-1], [width/2, int(0.5*height)], [width-1, height-1]], dtype=np.int32)\n",
    "    region_of_interest_vertices = np.array( [[(width/7, height),(0.4*width, 0.6*height),(0.6*width, 0.6*height),(0.92*width, height)]], dtype=np.int32 )\n",
    "    cv2.fillPoly(mask, [region_of_interest_vertices], 1)\n",
    "    plt.imshow(mask)\n",
    "    ROI_thresholded = cv2.bitwise_and(image, mask)\n",
    "    return ROI_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perspactive_transform(img, warp=True):\n",
    "    offset = [150,0] # offset for dst points\n",
    "    # Grab the image shape\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    # define 4 corners of ROI\n",
    "    #corners = np.float32([[190,720],[589,470],[698,470],[1145,720]])\n",
    "    corners = np.float32([[200,720],[570,470],[722,470],[1130,720]])\n",
    "    # define 4 \n",
    "    src = np.float32([corners[0], corners[1], corners[2], corners[3]])\n",
    "    # define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "    dst = np.float32([[320,720], [320,1], [920, 1], [920, 720]])    \n",
    "    # use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    if warp:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(dst,src)\n",
    "    # use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "    \n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_thresholded_image(img):\n",
    "    #img=mpimg.imread('./test_images/straight_lines1.jpg')\n",
    "    \n",
    "    undistorted = cal_undistort(img)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Apply each of the thresholding functions\n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "    gray = to_grayscale(img)\n",
    "    gradx = abs_sobel_thresh(gray, orient='x', thresh_min=20, thresh_max=255)\n",
    "    #grady = abs_sobel_thresh(gray, orient='y', thresh_min=5, thresh_max=95)\n",
    "    rgb_binary = rgb_thresh(img)\n",
    "    dir_binary = dir_threshold(gray, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "    binary_hls = hls_select(img, s_thresh=(150, 255))\n",
    "    \n",
    "    channels = 255*np.dstack(( np.zeros_like(gradx), gradx, binary_hls)).astype('uint8')  \n",
    "    \n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    #combined[((gradx == 1) & (binary_hls == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    combined[((gradx == 1) & (dir_binary == 1)) | ((binary_hls == 1) & (rgb_binary == 1))] = 1\n",
    "    #combined[(binary_hls == 1) & (grady == 1) | (gradx == 1)] = 1\n",
    "    final_combined = 255*np.dstack((combined,combined,combined)).astype('uint8')\n",
    "    \n",
    "    image_ROI = mask_ROI(combined)\n",
    "    #image_ROI = to_grayscale(image_ROI)\n",
    "    \n",
    "    \n",
    "    warped, M = perspactive_transform(image_ROI)\n",
    "    \n",
    "    return warped,image_ROI,final_combined,gray,channels,binary_hls,dir_binary,rgb_binary,gradx\n",
    "\n",
    "img=plt.imread('./test_images/test5.jpg')\n",
    "warped,image_ROI,final_combined,gray,channels,binary_hls,dir_binary,rgb_binary,gradx = get_thresholded_image(img)\n",
    "#plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(2, 4, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(gradx)\n",
    "ax1.set_title('grad x', fontsize=30)\n",
    "ax2.imshow(dir_binary)\n",
    "ax2.set_title('dir_binary Image', fontsize=30)\n",
    "ax3.imshow(binary_hls)\n",
    "ax3.set_title('binary_hls', fontsize=30)\n",
    "ax4.imshow(channels)\n",
    "ax4.set_title('Stacked thresholds', fontsize=30)\n",
    "ax5.imshow(img)\n",
    "ax5.set_title('Original Image', fontsize=30)\n",
    "ax6.imshow(gray)\n",
    "ax6.set_title('gray+Undistorted Image', fontsize=30)\n",
    "ax7.imshow(image_ROI)\n",
    "ax7.set_title('ROI_thresholded', fontsize=30)\n",
    "ax8.imshow(final_combined)\n",
    "ax8.set_title('final combined', fontsize=30)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply the region of interest mask\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "height,width,_ = img.shape\n",
    "mask = np.zeros_like(img)\n",
    "#region_of_interest_vertices = np.array([[0,height-1], [width/2, int(0.5*height)], [width-1, height-1]], dtype=np.int32)\n",
    "region_of_interest_vertices = np.array( [[(width/7, height),(0.4*width, 0.6*height),(0.6*width, 0.6*height),(0.92*width, height)]], dtype=np.int32 )\n",
    "cv2.fillPoly(mask, [region_of_interest_vertices], (255,255,255))\n",
    "orig_ROI = cv2.bitwise_and(img, mask)\n",
    "warped_orig, M2 = perspactive_transform(orig_ROI)\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1,ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(warped_orig)\n",
    "ax1.set_title('warped_orig', fontsize=40)\n",
    "\n",
    "ax2.imshow(warped)\n",
    "ax2.set_title('warped', fontsize=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram\n",
    "The peaks int the histogram tell us about the likely position of the lanes in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def histogram(warped):\n",
    "    binary_warped = np.copy(warped)\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    #out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255   # if using l_channel to remove colors\n",
    "    out_img = 255*np.dstack((binary_warped,binary_warped,binary_warped)).astype('uint8')  # if using CV2.___2gray\n",
    "    plt.imshow(out_img)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    print(leftx_base, rightx_base)\n",
    "    plt.plot(histogram)\n",
    "    \n",
    "    return leftx_base,rightx_base,midpoint,out_img\n",
    "\n",
    "leftx_base,rightx_base,midpoint,out_img = histogram(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_lines(warped):\n",
    "    binary_warped = np.copy(warped)\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_base,rightx_base,midpoint,out_img = histogram(warped)\n",
    "    out_img__current = np.copy(out_img)\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 200\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 20) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 20) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        #print(len(good_left_inds),good_left_inds.shape,good_left_inds[:10])\n",
    "        #print(len(good_right_inds),good_right_inds.shape,good_right_inds[:10],\"\\n\")\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    #print(len(left_lane_inds[0]),len(left_lane_inds[8]))  # 0,1,2..8 windows\n",
    "    # Concatenate the arrays of indices (pixels inside windows)\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    #print(len(left_lane_inds))\n",
    "    \n",
    "    # Extract left and right line pixel positions within those windows\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    print(\"\\nleftx and lefty:\", leftx[:10], lefty[:10])  #random 10 pixels --testing purpose #comment out\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    print(\"\\n\", left_lane_inds[:10], nonzerox[left_lane_inds[:10]])  #X pos random 10 pixels --testing purpose #comment out\n",
    "    print(\"\\n\", left_lane_inds[:10], nonzeroy[left_lane_inds[:10]])  #Y pos random 10 pixels --testing purpose #comment out\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    print(len(left_fitx),left_fitx[:10])   #random 10 pixels --testing purpose #comment out\n",
    "    \n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    \n",
    "    return left_fit,right_fit,left_fitx,right_fitx,warped,left_lane_inds,right_lane_inds,margin\n",
    "    \n",
    "left_fit,right_fit,left_fitx,right_fitx,warped,left_lane_inds,right_lane_inds,margin = find_lines(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_nxtLines(left_fit,right_fit,warped):\n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    binary_warped = np.copy(warped)\n",
    "    \n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 50\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "    print(len(left_lane_inds),left_lane_inds[:10])   #random 10 pixels --testing purpose #comment out\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fit,right_fit,left_fitx,right_fitx,warped,left_lane_inds,right_lane_inds,margin\n",
    "\n",
    "left_fit,right_fit,left_fitx,right_fitx,warped,left_lane_inds,right_lane_inds,margin = find_nxtLines(left_fit,right_fit,warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_lane(left_fit,right_fit,warped,left_lane_inds,right_lane_inds,margin):\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    #out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    binary_warped = np.copy(warped)\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )    \n",
    "    out_img = 255*np.dstack((binary_warped,binary_warped,binary_warped)).astype('uint8')  # if using CV2.___2gray\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    plt.imshow(result)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "\n",
    "draw_lane(left_fit,right_fit,warped,left_lane_inds,right_lane_inds,margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the radius of curvature and center offset.\n",
    "The radius of curvature is computed according to the formula and method described in the classroom material. Since we perform the polynomial fit in pixels and whereas the curvature has to be calculated in real world meters, we have to use a pixel to meter transformation and recompute the fit again.\n",
    "The mean of the lane pixels closest to the car gives us the center of the lane. The center of the image gives us the position of the car. The difference between the 2 is the offset from the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define y-value where we want radius of curvature \n",
    "# I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "binary_warped = np.copy(warped)\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )    \n",
    "y_eval = np.max(ploty)\n",
    "left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "print(left_curverad, right_curverad)   #in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def radius_offset(left_fitx,right_fitx):\n",
    "    #we actually need to repeat this calculation after converting our x and y values to real world space (in meters)\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    #print(left_curverad, 'm', right_curverad, 'm') # in meters\n",
    "    \n",
    "    average_curverad = (left_curverad + right_curverad)/2\n",
    "    curvature_string = \"Radius of curvature averaged of left and right curve: %.2f m\" % average_curverad\n",
    "    #print(curvature_string)\n",
    "    \n",
    "    # Offset\n",
    "    #The offset of the lane center from the center of the image (converted from pixels to meters) is your distance from the center of the lane.\n",
    "    lane_center = (left_fitx[719] + right_fitx[719])/2\n",
    "    center_offset_pixels = abs(img_size[0]/2 - lane_center)\n",
    "    center_offset_meters = xm_per_pix*center_offset_pixels\n",
    "    #print(\"offset of cener camera from center of lane: \", center_offset_meters)\n",
    "    \n",
    "    return average_curverad, center_offset_meters\n",
    "\n",
    "average_curverad, center_offset_meters = radius_offset(left_fitx,right_fitx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#out_img = 255*np.dstack((binary_warped,binary_warped,binary_warped)).astype('uint8')  # if using CV2.___2gray\n",
    "#y_points = np.linspace(0, num_rows-1, num_rows)\n",
    "\n",
    "left_line_window = np.array(np.transpose(np.vstack([left_fitx, ploty])))\n",
    "\n",
    "right_line_window = np.array(np.flipud(np.transpose(np.vstack([right_fitx, ploty]))))\n",
    "\n",
    "line_points = np.vstack((left_line_window, right_line_window))\n",
    "print(len(line_points),'\\n',line_points[:10])\n",
    "\n",
    "cv2.fillPoly(out_img, np.int_([line_points]), [70,120, 0])\n",
    "#plt.imshow(out_img)\n",
    "\n",
    "image_unwrpd, M_inv = perspactive_transform(out_img, warp=False)\n",
    "\n",
    "result = cv2.addWeighted(img, 1, image_unwrpd, 0.5, 0)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(out_img, cmap='gray')\n",
    "ax1.set_title('warped detected', fontsize=40)\n",
    "ax2.imshow(image_unwrpd, cmap='gray')\n",
    "ax2.set_title('Unwarped ROI', fontsize=40)   #FYI only, not used anywhere in this secftion\n",
    "ax3.imshow(result)\n",
    "ax3.set_title('mapped output Image', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some global variables\n",
    "polyfit_left=None\n",
    "polyfit_right=None\n",
    "\n",
    "past_good_left_lines = []\n",
    "past_good_right_lines = []\n",
    "\n",
    "running_mean_difference_between_lines = 0\n",
    "\n",
    "def get_line_predictions(non_zeros_x, non_zeros_y, left_coordinates, right_coordinates, num_rows):\n",
    "    \"\"\"\n",
    "        Given ncoordinates of non-zeros pixels and coordinates of non-zeros pixels within the sliding windows,\n",
    "        this function generates a prediction for the lane line.\n",
    "    \"\"\"\n",
    "    left_x = non_zeros_x[left_coordinates]\n",
    "    left_y = non_zeros_y[left_coordinates]\n",
    "    \n",
    "    # If no pixels were found return None\n",
    "    if(left_y.size == 0 or left_x.size == 0):\n",
    "        return None, None\n",
    "\n",
    "    # Fit the polynomial\n",
    "    polyfit_left = np.polyfit(left_y, left_x, 2)\n",
    "\n",
    "    right_x = non_zeros_x[right_coordinates]\n",
    "    right_y = non_zeros_y[right_coordinates]\n",
    "    \n",
    "    # If no pixels were found return None\n",
    "    if(right_y.size == 0 or right_x.size == 0):\n",
    "        return None, None\n",
    "\n",
    "    # Fit the polynomial\n",
    "    polyfit_right = np.polyfit(right_y, right_x, 2)\n",
    "\n",
    "    # If no pixels were found return None\n",
    "    y_points = np.linspace(0, num_rows-1, num_rows)\n",
    "    \n",
    "    # Generate the lane lines from the polynomial fit\n",
    "    left_x_predictions = polyfit_left[0]*y_points**2 + polyfit_left[1]*y_points + polyfit_left[2]\n",
    "    right_x_predictions = polyfit_right[0]*y_points**2 + polyfit_right[1]*y_points + polyfit_right[2]\n",
    "    \n",
    "    return left_x_predictions, right_x_predictions\n",
    "\n",
    "def brute_search(warped):\n",
    "    \"\"\"\n",
    "        This function searches for lane lines from scratch.\n",
    "        Thresholding & performing a sliding window search.\n",
    "    \"\"\"\n",
    "    non_zeros = warped.nonzero()\n",
    "    non_zeros_y = non_zeros[0]\n",
    "    non_zeros_x = non_zeros[1]\n",
    "    \n",
    "    num_rows = warped.shape[0]\n",
    "    \n",
    "    histogram = np.sum(warped[warped.shape[0]/2:,:], axis=0)\n",
    "\n",
    "    half_width = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:half_width])\n",
    "    rightx_base = np.argmax(histogram[half_width:]) + half_width\n",
    "\n",
    "    num_windows = 10\n",
    "    window_height = np.int(num_rows/num_windows)\n",
    "    window_half_width = 50\n",
    "\n",
    "    min_pixels = 100\n",
    "\n",
    "    left_coordinates = []\n",
    "    right_coordinates = []\n",
    "\n",
    "    for window in range(num_windows):\n",
    "        y_max = num_rows - window*window_height\n",
    "        y_min = num_rows - (window+1)* window_height\n",
    "\n",
    "        left_x_min = leftx_base - window_half_width\n",
    "        left_x_max = leftx_base + window_half_width\n",
    "\n",
    "        good_left_window_coordinates = ((non_zeros_x >= left_x_min) & (non_zeros_x <= left_x_max) & (non_zeros_y >= y_min) & (non_zeros_y <= y_max)).nonzero()[0]\n",
    "        left_coordinates.append(good_left_window_coordinates)\n",
    "\n",
    "        if len(good_left_window_coordinates) > min_pixels:\n",
    "            leftx_base = np.int(np.mean(non_zeros_x[good_left_window_coordinates]))\n",
    "\n",
    "        right_x_min = rightx_base - window_half_width\n",
    "        right_x_max = rightx_base + window_half_width\n",
    "\n",
    "        good_right_window_coordinates = ((non_zeros_x >= right_x_min) & (non_zeros_x <= right_x_max) & (non_zeros_y >= y_min) & (non_zeros_y <= y_max)).nonzero()[0]\n",
    "        right_coordinates.append(good_right_window_coordinates)\n",
    "\n",
    "        if len(good_right_window_coordinates) > min_pixels:\n",
    "            rightx_base = np.int(np.mean(non_zeros_x[good_right_window_coordinates]))\n",
    "\n",
    "    left_coordinates = np.concatenate(left_coordinates)\n",
    "    right_coordinates = np.concatenate(right_coordinates)\n",
    "    \n",
    "    left_x_predictions, right_x_predictions = get_line_predictions(non_zeros_x, non_zeros_y, left_coordinates, right_coordinates, num_rows)\n",
    "    return left_x_predictions, right_x_predictions\n",
    "\n",
    "def get_averaged_line(previous_lines, new_line):\n",
    "    \"\"\"\n",
    "        This function computes an averaged lane line by averaging over previous good frames.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of frames to average over\n",
    "    num_frames = 12\n",
    "    \n",
    "    if new_line is None:\n",
    "        # No line was detected\n",
    "        \n",
    "        if len(previous_lines) == 0:\n",
    "            # If there are no previous lines, return None\n",
    "            return previous_lines, None\n",
    "        else:\n",
    "            # Else return the last line\n",
    "            return previous_lines, previous_lines[-1]\n",
    "    else:\n",
    "        if len(previous_lines) < num_frames:\n",
    "            # we need at least num_frames frames to average over\n",
    "            previous_lines.append(new_line)\n",
    "            return previous_lines, new_line\n",
    "        else:\n",
    "            # average over the last num_frames frames\n",
    "            previous_lines[0:num_frames-1] = previous_lines[1:]\n",
    "            previous_lines[num_frames-1] = new_line\n",
    "            new_line = np.zeros_like(new_line)\n",
    "            for i in range(num_frames):\n",
    "                new_line += previous_lines[i]\n",
    "            new_line /= num_frames\n",
    "            return previous_lines, new_line\n",
    "        \n",
    "        \n",
    "def get_mean_distance_between_lines(left_line, right_line, running_average):\n",
    "    \"\"\"\n",
    "        Returns running weighted average of simple difference between left and right lines\n",
    "    \"\"\"\n",
    "    mean_distance = np.mean(right_line - left_line)\n",
    "    if running_average == 0:\n",
    "        running_average = mean_distance\n",
    "    else:\n",
    "        running_average = 0.9*running_average + 0.1*mean_distance\n",
    "    return running_average\n",
    "    \n",
    "\n",
    "def pipeline_final(img):\n",
    "    # global variables to store the polynomial coefficients of the line detected in the last frame\n",
    "    global polyfit_right\n",
    "    global polyfit_left\n",
    "    \n",
    "    # global variables to store the line coordinates in previous n (=4) frames\n",
    "    global past_good_right_lines\n",
    "    global past_good_left_lines\n",
    "    \n",
    "    # global variable which contains running average of the mean difference between left and right lanes\n",
    "    global running_mean_difference_between_lines\n",
    "    \n",
    "    image_shape = img.shape\n",
    "    img_size = (image_shape[1], image_shape[0])\n",
    "    \n",
    "    # get thresholded image\n",
    "    thresholded = get_thresholded_image(img)\n",
    "    \n",
    "    # perform a perspective transform\n",
    "    warped, M = perspactive_transform(image_ROI)\n",
    "    #warped = cv2.warpPerspective(thresholded, M, img_size , flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    #out_img = np.dstack((warped, warped, warped))*255\n",
    "    out_img = 255*np.dstack((binary_warped,binary_warped,binary_warped)).astype('uint8')  # if using CV2.___2gray\n",
    "    non_zeros = warped.nonzero()\n",
    "    non_zeros_y = non_zeros[0]\n",
    "    non_zeros_x = non_zeros[1]\n",
    "    \n",
    "    num_rows = warped.shape[0]\n",
    "    y_points = np.linspace(0, num_rows-1, num_rows)\n",
    "    \n",
    "    if (polyfit_left is None) or (polyfit_right is None):\n",
    "        # If the polynomial coefficients of the previous frames are None then perform a brute force search\n",
    "        brute = True\n",
    "        left_x_predictions, right_x_predictions = brute_search(warped)\n",
    "    else:\n",
    "        # Else search in a margin of 100 pixels on each side of the pervious polynomial fit\n",
    "        brute = False\n",
    "        margin = 100\n",
    "        left_x_predictions = polyfit_left[0]*non_zeros_y**2 + polyfit_left[1]*non_zeros_y + polyfit_left[2]\n",
    "        left_coordinates = ((non_zeros_x >= left_x_predictions - margin) & (non_zeros_x <= left_x_predictions + margin)).nonzero()[0]\n",
    "\n",
    "        right_x_predictions = polyfit_right[0]*non_zeros_y**2 + polyfit_right[1]*non_zeros_y + polyfit_right[2]\n",
    "        right_coordinates = ((non_zeros_x >= right_x_predictions - margin) & (non_zeros_x <= right_x_predictions + margin)).nonzero()[0]\n",
    "        \n",
    "        left_x_predictions, right_x_predictions = get_line_predictions(non_zeros_x, non_zeros_y, left_coordinates, right_coordinates, num_rows)\n",
    "    \n",
    "    if (left_x_predictions is None or right_x_predictions is None):\n",
    "        if not brute:\n",
    "            left_x_predictions, right_x_predictions = brute_search(warped)\n",
    "            \n",
    "    bad_lines = False\n",
    "            \n",
    "    if (left_x_predictions is None or right_x_predictions is None):\n",
    "        bad_lines = True\n",
    "    else:\n",
    "        mean_difference = np.mean(right_x_predictions - left_x_predictions)\n",
    "        \n",
    "        if running_mean_difference_between_lines == 0:\n",
    "            running_mean_difference_between_lines = mean_difference\n",
    "        \n",
    "        if (mean_difference < 0.7*running_mean_difference_between_lines or mean_difference > 1.3*running_mean_difference_between_lines):\n",
    "            bad_lines = True\n",
    "            if not brute:\n",
    "                left_x_predictions, right_x_predictions = brute_search(warped)\n",
    "                if (left_x_predictions is None or right_x_predictions is None):\n",
    "                    bad_lines = True\n",
    "                else:\n",
    "                    mean_difference = np.mean(right_x_predictions - left_x_predictions)\n",
    "                    if (mean_difference < 0.7*running_mean_difference_between_lines or mean_difference > 1.3*running_mean_difference_between_lines):\n",
    "                        bad_lines = True\n",
    "                    else:\n",
    "                        bad_lines = False\n",
    "        else:\n",
    "            bad_lines = False\n",
    "            \n",
    "    if bad_lines:\n",
    "        polyfit_left = None\n",
    "        polyfit_right = None\n",
    "        if len(past_good_left_lines) == 0 and len(past_good_right_lines) == 0:\n",
    "            return img\n",
    "        else:\n",
    "            left_x_predictions = past_good_left_lines[-1]\n",
    "            right_x_predictions = past_good_right_lines[-1]\n",
    "    else:\n",
    "        past_good_left_lines, left_x_predictions = get_averaged_line(past_good_left_lines, left_x_predictions)\n",
    "        past_good_right_lines, right_x_predictions = get_averaged_line(past_good_right_lines, right_x_predictions)\n",
    "        mean_difference = np.mean(right_x_predictions - left_x_predictions)\n",
    "        running_mean_difference_between_lines = 0.9*running_mean_difference_between_lines + 0.1*mean_difference\n",
    "    \n",
    "    left_line_window = np.array(np.transpose(np.vstack([left_x_predictions, y_points])))\n",
    "    right_line_window = np.array(np.flipud(np.transpose(np.vstack([right_x_predictions, y_points]))))\n",
    "    \n",
    "    # compute the radius of curvature\n",
    "    average_curverad, center_offset_meters = radius_offset(left_x_predictions,right_x_predictions)\n",
    "    curvature_string = \"Radius of curvature: %.2f m\" % average_curverad\n",
    "    # print the offset from the center\n",
    "    offset_string = \"Center offset: %.2f m\" % center_offset_meters\n",
    "    \n",
    "    poly_points = np.vstack([left_line_window, right_line_window])\n",
    "    \n",
    "    cv2.fillPoly(out_img, np.int_([poly_points]), [0,255, 0])\n",
    "    \n",
    "    #unwarped = cv2.warpPerspective(out_img, M_inv, img_size , flags=cv2.INTER_LINEAR)\n",
    "    image_unwrpd, M_inv = perspactive_transform(out_img, warp=False)\n",
    "    \n",
    "    #print(img.shape, image_unwrpd.shape)\n",
    "\n",
    "    result = cv2.addWeighted(img, 1, image_unwrpd, 0.5, 0)\n",
    "    \n",
    "    cv2.putText(result,curvature_string , (100, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), thickness=2)\n",
    "    cv2.putText(result, offset_string, (100, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), thickness=2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#img = mpimg.imread('test_images/test2.jpg')\n",
    "img=plt.imread('./test_images/test5.jpg')\n",
    "\n",
    "# Reinitialize some global variables.\n",
    "polyfit_left = None\n",
    "polyfit_right = None\n",
    "past_good_right_lines = []\n",
    "past_good_left_lines = []\n",
    "running_mean_difference_between_lines = 0\n",
    "\n",
    "# Apply pipeline\n",
    "processed = pipeline_final(img)\n",
    "\n",
    "# Plot the 2 images\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(processed, cmap='gray')\n",
    "ax2.set_title('Processed Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Process Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "#from signal import signal, SIGPIPE, SIG_DFL\n",
    "#signal(SIGPIPE,SIG_DFL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reinitialize some global variables.\n",
    "polyfit_left = None\n",
    "polyfit_right = None\n",
    "past_good_right_lines = []\n",
    "past_good_left_lines = []\n",
    "running_mean_difference_between_lines = 0\n",
    "\n",
    "video_in = VideoFileClip(\"project_video.mp4\")\n",
    "video_out = 'project_video_output.mp4'\n",
    "out_clip = video_in.fl_image(pipeline_final) #NOTE: this function expects color images!!\n",
    "%time out_clip.write_videofile(video_out, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
